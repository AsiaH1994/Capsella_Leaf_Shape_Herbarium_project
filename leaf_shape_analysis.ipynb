{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reading in lists of files in folders \n",
    "from os import listdir \n",
    "from os.path import isfile, join\n",
    "\n",
    "# for working with numpy functionalities\n",
    "import numpy as np\n",
    "\n",
    "# for plotting with matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# for mathematical operations\n",
    "import math \n",
    "\n",
    "# for interpolating points\n",
    "from scipy.interpolate import interp1d \n",
    "\n",
    "# for Procrustes analysis\n",
    "from scipy.spatial import procrustes #\n",
    "\n",
    "# for principal component analysis\n",
    "from sklearn.decomposition import PCA \n",
    "\n",
    "# for dataframe capabilities\n",
    "import pandas as pd\n",
    "\n",
    "# for hue and other plotting capabilities\n",
    "import seaborn as sns\n",
    "\n",
    "# to save csv \n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########\n",
    "# FUNCTION\n",
    "##########\n",
    "\n",
    "# define a function to return equally spaced, interpolated points for a given polyline\n",
    "# inputs: arrays of x and y values for a polyline, number of points to interpolate\n",
    "# ouputs: interpolated points along the polyline, inclusive of start and end points, as arrays\n",
    "\n",
    "def interpolation(x, y, number): \n",
    "\n",
    "    distance = np.cumsum(np.sqrt( np.ediff1d(x, to_begin=0)**2 + np.ediff1d(y, to_begin=0)**2 ))\n",
    "    distance = distance/distance[-1]\n",
    "\n",
    "    fx, fy = interp1d( distance, x ), interp1d( distance, y )\n",
    "\n",
    "    alpha = np.linspace(0, 1, number)\n",
    "    x_regular, y_regular = fx(alpha), fy(alpha)\n",
    "    \n",
    "    return x_regular, y_regular\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide path to shapes folder\n",
    "shapes_path = \"file-path\"\n",
    "\n",
    "# retrieve a list of shape file names\n",
    "shape_files = [f for f in listdir(shapes_path) if isfile(join(shapes_path, f))] \n",
    "# sort the file names alphanumerically so they correspond to landmark files\n",
    "shape_files.sort()\n",
    "\n",
    "# create a list to store names\n",
    "shapes = []\n",
    "\n",
    "# for each shape file\n",
    "for i in range(len(shape_files)):\n",
    "    \n",
    "    # index the current file name, and index the first two characters and append to the shapes list\n",
    "    shapes.append(shape_files[i][0:-5])\n",
    "    \n",
    "# a list of arrays, to store 2D arrays of shape data points for each shape\n",
    "shape_data = []\n",
    "\n",
    "# a list of arrays, to store 2D arrays of landmark points for each shape\n",
    "landmark_data = []\n",
    "\n",
    "# for each shape\n",
    "for i in range(len(shapes)):\n",
    "    \n",
    "    # load in the shape data as a 2D numpy array\n",
    "    current_shape_data = np.loadtxt(shapes_path + \"/\" + shape_files[i])\n",
    "    \n",
    "    resolution = np.shape(current_shape_data)[0]\n",
    "    \n",
    "    # increase leaf \"resolution\"\n",
    "    high_res_x, high_res_y = interpolation(current_shape_data[:,0], current_shape_data[:,1], resolution)\n",
    "    \n",
    "    highres_shape = np.column_stack((high_res_x, high_res_y))\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    PCs = pca.fit_transform(highres_shape)\n",
    "    \n",
    "    # append the 2D array to the shape_data list\n",
    "    shape_data.append(PCs)\n",
    "\n",
    "\n",
    "    origin = PCs[0,:]\n",
    "\n",
    "    if origin[0] > 0:\n",
    "        min_ind = np.argmin(PCs[:,0],axis=None,out=None)\n",
    "        tip = PCs[min_ind,:]\n",
    "    else:\n",
    "        max_ind = np.argmax(PCs[:,0],axis=None,out=None)\n",
    "        tip = PCs[max_ind,:]\n",
    "        \n",
    "    current_landmarks = np.row_stack((origin, tip))\n",
    "    \n",
    "    landmark_data.append(current_landmarks)\n",
    "    \n",
    "    print(current_shape_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(shape_files)\n",
    "\n",
    "shapefilesdf = pd.DataFrame(shape_files) \n",
    "\n",
    "shapefilesdf.to_csv('file-path-shapefilenames.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the indices of the points in the shape data that correspond to the base and tip landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################\n",
    "# we need to find the points in the shape data file that are closest to the base and tip landmarks\n",
    "# 1. calculate the euclidean distance of each shape data point to the base and tip landmark\n",
    "# and store the indices of the shape points, so we know which shape data points to use as landmarks\n",
    "# 2. use indices to plot out base and tip landmarks and make sure we were successful\n",
    "\n",
    "###########################################################################################\n",
    "# 1. calculate the euclidean distance of each shape data point to the base and tip landmark\n",
    "# and store the indices of the shape points, so we know which shape data points to use as landmarks\n",
    "\n",
    "# a list of lists,\n",
    "# to store the indices of the points in the shape file closest to the base and tip landmarks\n",
    "# for each shape\n",
    "landmark_indices = []\n",
    "\n",
    "# for each shape\n",
    "for i in range(len(shapes)):\n",
    "    \n",
    "    # select data points in array for the current shape\n",
    "    current_shape = shape_data[i]\n",
    "    \n",
    "    # select landmark points in array for the current shape\n",
    "    current_landmarks = landmark_data[i]\n",
    "    \n",
    "    # create a list to store the distance of each shape point to the base landmark\n",
    "    base_distances = []\n",
    "    # create a list to store the distance of each shape point to the tip landmark\n",
    "    tip_distances = []\n",
    "    \n",
    "    # for the number of points in the shape_data file\n",
    "    # use np.shape, with \"0\" to count number of rows, or points in the data\n",
    "    for j in range(np.shape(current_shape)[0]):\n",
    "        \n",
    "        # calculate the euclidean distance of each shape point to\n",
    "        # the base landmark and append to the base distance list\n",
    "        base_distances.append(np.sqrt(\n",
    "            (current_landmarks[0,0]-current_shape[j,0])**2 + \n",
    "            (current_landmarks[0,1]-current_shape[j,1])**2))\n",
    "        \n",
    "        # calculate the euclidean distance of each shape point to\n",
    "        # the tip landmark and append to the tipdistance list\n",
    "        tip_distances.append(np.sqrt(\n",
    "            (current_landmarks[1,0]-current_shape[j,0])**2 + \n",
    "            (current_landmarks[1,1]-current_shape[j,1])**2))\n",
    "    \n",
    "    # find the indices of the minimum distance of the base and tip to shape points\n",
    "    # append a list of the base and tip minimum indices to the list landmark indices\n",
    "    landmark_indices.append([base_distances.index(min(base_distances)),\n",
    "               tip_distances.index(min(tip_distances))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "# 2. use indices to plot out base and tip landmarks and make sure we were successful\n",
    "\n",
    "# for each shape\n",
    "for i in range(16):\n",
    "    \n",
    "    # get current plot number for plt.subplot, + 1 because indexing starts at 0\n",
    "    plot_num = i + 1 \n",
    "    \n",
    "    # select data points for the current shape\n",
    "    current_shape = shape_data[i]\n",
    "    \n",
    "    # specify subplot\n",
    "    plt.subplot(4,4,plot_num) \n",
    "    \n",
    "    # plot shape name above each shape (need to modify so no overlap still)\n",
    "    plt.title(shapes[i], fontsize=8) \n",
    "    \n",
    "    # use fill to plot each shape, index on the columns of the arrays for x and y coords\n",
    "    plt.fill(current_shape[:,0], current_shape[:,1])\n",
    "    \n",
    "    # use the landmark indices to plot the base landmark in orange\n",
    "    # the ith index in landmark_indices indicates the index of the shape data point corresponding to base\n",
    "    plt.scatter(current_shape[landmark_indices[i][0],0], current_shape[landmark_indices[i][0],1], c=\"orange\")\n",
    "    \n",
    "    # use the landmark indices to plot the tip landmark in magenta\n",
    "    # the ith index in landmark_indices indicates the index of the shape data point corresponding to tip\n",
    "    plt.scatter(current_shape[landmark_indices[i][1],0], current_shape[landmark_indices[i][1],1], c=\"magenta\")\n",
    "    \n",
    "    # set axes equal in scale and turn off display axes\n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(16):\n",
    "    \n",
    "    # get current plot number for plt.subplot, + 1 because indexing starts at 0\n",
    "    plot_num = i + 1 \n",
    "    \n",
    "    # select data points for the current shape\n",
    "    current_shape = shape_data[i]\n",
    "    \n",
    "    # specify subplot\n",
    "    plt.subplot(4,4,plot_num) \n",
    "\n",
    "    # use fill to plot each shape, index on the columns of the arrays for x and y coords\n",
    "    plt.fill(current_shape[:,0], current_shape[:,1])\n",
    "    # set axes equal in scale and turn off display axes\n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reindex the coordinate values so that they begin with the base at index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# The problem is that the base landmark doesn't start at index position 0\n",
    "# the base is at an arbitrary index value, and the zero index is also\n",
    "# at an arbitrary position in the shape. We need to reindex to the base being index = 0\n",
    "# 1. Reindex the shape data\n",
    "# 2. Reindex the landmark data\n",
    "\n",
    "############################\n",
    "# 1. Reindex the shape data\n",
    "\n",
    "# a list of arrays, with a 2D array of reindexed x and y coordinates for each shape\n",
    "reindexed_data = []\n",
    "\n",
    "# for each shape, s\n",
    "for s in range(len(shapes)):\n",
    "    \n",
    "    # get number of coordinate values for the current shape\n",
    "    num_coords = np.shape(shape_data[s])[0] \n",
    "    \n",
    "    # get the zeroth index to start at (the base)\n",
    "    zero_index = landmark_indices[s][0] \n",
    "\n",
    "    # create an array to store new x and y vals using np.zeros\n",
    "    reindexed_arr = np.zeros((num_coords,2)) \n",
    "\n",
    "    # for the number of points in the shape, i\n",
    "    for i in range(num_coords):\n",
    "\n",
    "        # get current index\n",
    "        curr_ind = i \n",
    "        \n",
    "        # get the new index to use\n",
    "        new_ind = (i - zero_index)%num_coords \n",
    "        \n",
    "        # store the value at the new index position\n",
    "        reindexed_arr[new_ind,:] = shape_data[s][curr_ind,:] \n",
    "        \n",
    "    # append the reindexed array into the shape_data list\n",
    "    reindexed_data.append(reindexed_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# 2. Reindex the landmark data\n",
    "\n",
    "# a list of lists, with lists of indices for each shape\n",
    "reindexed_indices = []\n",
    "\n",
    "# for each shape, s\n",
    "for s in range(len(shapes)):\n",
    "    \n",
    "    # get number of coordinate values\n",
    "    num_coords = np.shape(shape_data[s])[0] \n",
    "    \n",
    "    # get the zeroth, base index\n",
    "    zero_index = landmark_indices[s][0]\n",
    "    \n",
    "    # get the tip index\n",
    "    tip_index = landmark_indices[s][1]\n",
    "    \n",
    "    # get the new base index (it should be 0 in all cases, by definition)\n",
    "    new_base = (zero_index - zero_index)%num_coords\n",
    "    \n",
    "    # get the new tip index\n",
    "    new_tip = (tip_index - zero_index)%num_coords\n",
    "    \n",
    "    # create new indices list\n",
    "    new_indices = [new_base, new_tip]\n",
    "        \n",
    "    # append the reindexed indices into the reindexed_indices list\n",
    "    reindexed_indices.append(new_indices)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotate shapes to the same angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# We want to rotate all the shapes to the same angle\n",
    "# Procrustes analysis will take care of rotation\n",
    "# however, when we reconstruct the leaves, we want them at\n",
    "# an angle we have chosen, not an arbitrary one\n",
    "# so we rotate the data before we do Procrustes alignment\n",
    "\n",
    "#####################################################################\n",
    "# 1. Using tip and base landmarks, rotate leaves to the desired angle\n",
    "# 2. Plot out leaves and check that we were successful\n",
    "\n",
    "###########\n",
    "# FUNCTIONS\n",
    "###########\n",
    "\n",
    "# define a function to find the angle between 3 points anti-clockwise in degrees, p2 being the vertex\n",
    "# and p1 being the left hand of the angle and p3 a reference point for directionality\n",
    "# inputs: three angle points, as tuples\n",
    "# output: angle in degrees\n",
    "\n",
    "def angle_between(p1, p2, p3):\n",
    "    x1, y1 = p1\n",
    "    x2, y2 = p2\n",
    "    x3, y3 = p3\n",
    "    deg1 = (360 + math.degrees(math.atan2(x1 - x2, y1 - y2))) % 360\n",
    "    deg2 = (360 + math.degrees(math.atan2(x3 - x2, y3 - y2))) % 360\n",
    "    return deg2 - deg1 if deg1 <= deg2 else 360 - (deg1 - deg2)\n",
    "\n",
    "# define a function to rotate 2D x and y coordinate points around the origin\n",
    "# inputs: x and y vals (can take pandas dataframe columns) and the degrees (positive, anticlockwise) to rotate\n",
    "# target_angle is the angle you want to rotate to, in degrees\n",
    "# outputs: rotated and y vals\n",
    "\n",
    "def rotate_points(xvals, yvals, degrees, target_angle):\n",
    "    \n",
    "    angle_to_move = target_angle - degrees \n",
    "    rads = np.deg2rad(angle_to_move)\n",
    "    \n",
    "    new_xvals = xvals*np.cos(rads)-yvals*np.sin(rads)\n",
    "    new_yvals = xvals*np.sin(rads)+yvals*np.cos(rads)\n",
    "    \n",
    "    return new_xvals, new_yvals\n",
    "\n",
    "#####################################################################\n",
    "# 1. Using tip and base landmarks, rotate leaves to the desired angle\n",
    "\n",
    "#################\n",
    "# set the angle to rotate to in degrees\n",
    "target_angle = 180\n",
    "#################\n",
    "\n",
    "# a list of arrays, a list of 2D arrays containing the rotated x and y coordinates for each shape\n",
    "rotated_data = [] \n",
    "\n",
    "# for the number of shapes\n",
    "for i in range(len(shapes)):\n",
    "\n",
    "    # the left hand of the angle, the point that determines the angle, the tip in this case\n",
    "    determining_point = reindexed_data[i][reindexed_indices[i][1],:] \n",
    "    # the vertex of the angle, the point the angle rotates around, the base in this case\n",
    "    origin_point = reindexed_data[i][reindexed_indices[i][0],:] \n",
    "    # the reference side of the angle that determines direction, \n",
    "    # we use the base but shift the x value positively in our case\n",
    "    reference_point = (reindexed_data[i][reindexed_indices[i][0],0]+1,reindexed_data[i][reindexed_indices[i][0],1])\n",
    "\n",
    "    # using the three calculated points above, calculate the angle in degrees\n",
    "    angle = angle_between(determining_point, origin_point, reference_point) # calculate current angle\n",
    "\n",
    "    # use the rotate_points function to rotate the points to the desired new angle\n",
    "    rotated_xvals, rotated_yvals = rotate_points(reindexed_data[i][:,0], reindexed_data[i][:,1], angle, target_angle)\n",
    "\n",
    "    # put the x and y coordiantes back together again as a 2D numpy array\n",
    "    rotated_coords = np.column_stack((rotated_xvals, rotated_yvals))\n",
    "    \n",
    "    # append the rotated 2D coordinates for the current shape to the list\n",
    "    rotated_data.append(rotated_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# 2. Plot out leaves and check that we were successful\n",
    "\n",
    "# for each shape\n",
    "for i in range(16):\n",
    "    \n",
    "    # get current plot number for plt.subplot, + 1 because indexing starts at 0\n",
    "    plot_num = i + 1 \n",
    "    \n",
    "    # select data points for the current shape\n",
    "    current_shape = rotated_data[i]\n",
    "    \n",
    "    # specify subplot\n",
    "    plt.subplot(4,4,plot_num) \n",
    "    \n",
    "    # plot shape name above each shape (need to modify so no overlap still)\n",
    "    plt.title(shapes[i], fontsize=8) \n",
    "    \n",
    "    # use fill to plot each shape, index on the columns of the arrays for x and y coords\n",
    "    plt.fill(current_shape[:,0], current_shape[:,1])\n",
    "    \n",
    "    # use the landmark indices to plot the base landmark in orange\n",
    "    # the ith index in landmark_indices indicates the index of the shape data point corresponding to base\n",
    "    plt.scatter(current_shape[reindexed_indices[i][0],0], current_shape[reindexed_indices[i][0],1], c=\"orange\")\n",
    "    \n",
    "    # use the landmark indices to plot the tip landmark in magenta\n",
    "    # the ith index in landmark_indices indicates the index of the shape data point corresponding to tip\n",
    "    plt.scatter(current_shape[reindexed_indices[i][1],0], current_shape[reindexed_indices[i][1],1], c=\"magenta\")\n",
    "    \n",
    "    # set axes equal in scale and turn off display axes\n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "#plt.savefig('/Users/asiahightower/Desktop/herbarium_paper_figures/individual_leaves/rotated_leaves.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each shape\n",
    "for i in range(20):\n",
    "    \n",
    "    # get current plot number for plt.subplot, + 1 because indexing starts at 0\n",
    "    plot_num = i + 1 \n",
    "    \n",
    "    # select data points for the current shape\n",
    "    current_shape = rotated_data[i]\n",
    "    \n",
    "    # specify subplot\n",
    "    plt.subplot(4,5,plot_num) \n",
    "    plt.fill(current_shape[:,0], current_shape[:,1])\n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "#plt.savefig('/Users/asiahightower/Desktop/20_leaf_images.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use interpolation to create pseudolandmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "# 1. before we do Procrustes analysis, we need to create the same number of interpolated\n",
    "# points that correspond with each other between the tip and the base on each side of the leaf\n",
    "# 2. Check that the interpolation was done correctly\n",
    "\n",
    "##########\n",
    "# FUNCTION\n",
    "##########\n",
    "\n",
    "# define a function to return equally spaced, interpolated points for a given polyline\n",
    "# inputs: arrays of x and y values for a polyline, number of points to interpolate\n",
    "# ouputs: interpolated points along the polyline, inclusive of start and end points, as arrays\n",
    "\n",
    "def interpolation(x, y, number): \n",
    "\n",
    "    distance = np.cumsum(np.sqrt( np.ediff1d(x, to_begin=0)**2 + np.ediff1d(y, to_begin=0)**2 ))\n",
    "    distance = distance/distance[-1]\n",
    "\n",
    "    fx, fy = interp1d( distance, x ), interp1d( distance, y )\n",
    "\n",
    "    alpha = np.linspace(0, 1, number)\n",
    "    x_regular, y_regular = fx(alpha), fy(alpha)\n",
    "    \n",
    "    return x_regular, y_regular\n",
    "\n",
    "\n",
    "########################################################################################\n",
    "# 1. before we do Procrustes analysis, we need to create the same number of interpolated\n",
    "# points that correspond with each other between the tip and the base on each side of the leaf\n",
    "\n",
    "#################\n",
    "# set the number of points to interpolate on EACH SIDE of the leaf (total point number will be double)\n",
    "point_number = 100\n",
    "#################\n",
    "\n",
    "# a list of arrays, a list of 2D arrays containing the interpolated x and y coordinates for each shape\n",
    "interpolated_data = [] \n",
    "\n",
    "for i in range(len(shapes)):\n",
    "\n",
    "    # interpolate between the base to the point before the tip for the given point number\n",
    "    base_to_tip_x, base_to_tip_y = interpolation(rotated_data[i][reindexed_indices[i][0]:(reindexed_indices[i][1])-1,0], \n",
    "                                         rotated_data[i][reindexed_indices[i][0]:(reindexed_indices[i][1])-1,1], \n",
    "                                         point_number)\n",
    "\n",
    "    # interpolate between the tip to the last point for the given point number\n",
    "    tip_to_base_x, tip_to_base_y = interpolation(rotated_data[i][reindexed_indices[i][1]:,0], \n",
    "                                         rotated_data[i][reindexed_indices[i][1]:,1], \n",
    "                                         point_number)\n",
    "\n",
    "\n",
    "    # combine each set of points into 2D numpy arrays of x and y coordinates\n",
    "    base_to_tip_coords = np.column_stack((base_to_tip_x, base_to_tip_y))\n",
    "    tip_to_base_coords = np.column_stack((tip_to_base_x, tip_to_base_y))\n",
    "\n",
    "    # combine both sets of points into a single 2D array for the overall shape\n",
    "    interpolated_coords = np.row_stack((base_to_tip_coords, tip_to_base_coords))\n",
    "    \n",
    "    # append the array of interpolated points to the list\n",
    "    interpolated_data.append(interpolated_coords)\n",
    "    \n",
    "    #print(tip_to_base_coords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting landmark data from interpolated_data array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(interpolated_data))\n",
    "print(np.shape(shapes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my2darray = np.reshape(interpolated_data, (523, 200*2))\n",
    "np.shape(my2darray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = np.column_stack([shapes,my2darray])\n",
    "np.shape(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.DataFrame(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.to_csv('file-path-landmark_dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# 2. Check that the interpolation was done correctly\n",
    "\n",
    "# for each shape\n",
    "for i in range(16):\n",
    "    \n",
    "    # get current plot number for plt.subplot, + 1 because indexing starts at 0\n",
    "    plot_num = i + 1 \n",
    "    \n",
    "    # select data points for the current shape\n",
    "    current_shape = interpolated_data[i]\n",
    "    \n",
    "    # specify subplot\n",
    "    plt.subplot(4,4,plot_num) \n",
    "    \n",
    "    # plot shape name above each shape (need to modify so no overlap still)\n",
    "    plt.title(shapes[i], fontsize=8) \n",
    "    \n",
    "    # use scatter to check interpolated points\n",
    "    plt.scatter(current_shape[:,0], current_shape[:,1], s=1)\n",
    "    \n",
    "    # set axes equal in scale and turn off display axes\n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# 2. Check that the interpolation was done correctly\n",
    "    # select data points for the current shape\n",
    "current_shape = interpolated_data[9]\n",
    "    \n",
    "    # use scatter to check interpolated points\n",
    "plt.fill(current_shape[:,0], current_shape[:,1])\n",
    "    \n",
    "    # set axes equal in scale and turn off display axes\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.axis(\"off\")\n",
    "#plt.savefig('/Users/asiahightower/Desktop/herbarium_paper_figures/individual_leaves/uppermidwest_michigan.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate mean Generalized Procrustes Analysis (GPA) shape\n",
    "\n",
    "Procrustes analysis aligns two shapes to each other by minimizing their overall distance. This Procrustes distance can be used as a measure of how similar to shapes are to each other. When aligning many shapes to each other as we are doing here, we need to find an overall mean leaf to align all leaves to. The algorithm to calculate this mean leaf for many leaves is called Generalized Procrustes Analysis (GPA). The GPA algorithm works by starting with an arbitrary reference leaf, usually the first sample. All leaves are aligned to the reference and a mean is calculated. This new mean leaf is then used as a new reference, again which all leaves are aligned to and a new mean is calculated which serves as the new reference. When the Procrustes distance between the new mean and the old mean reach an arbitrarily low Procrustes distance value, we use the mean as the Procrustes mean to align all the leaves to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_ind = 0 # select a reference index to calculate procrustes distances to\n",
    "ref_shape = interpolated_data[ref_ind] # select the reference shape\n",
    "landmark_number = np.shape(interpolated_data[0])[0] # get number of landmarks from first shape (it's the same for all shapes)\n",
    "\n",
    "mean_diff = 10**(-30) # set a Procrustes distance between means to stop the algorithm, arbitrarily small\n",
    "\n",
    "old_mean = ref_shape # for the first comparison between means, set old_mean to an arbitrary reference shape\n",
    "\n",
    "d = 1000000 # set d, the distance, initially arbitraily high\n",
    "\n",
    "while d > mean_diff: # set boolean criterion for Procrustes distance between mean to stop calculations\n",
    "    \n",
    "    arr = np.zeros( ((len(shapes)),landmark_number,2) ) # empty 3D array: # samples, total number of landmarks, 2 coord vals\n",
    "\n",
    "    for i in range(len(shapes)): # for each leaf shape \n",
    "\n",
    "        s1, s2, distance = procrustes(old_mean, interpolated_data[i]) # calculate procrustes adjusted shape to ref for current leaf\n",
    "        arr[i] = s2 # store procrustes adjusted shape to array\n",
    "\n",
    "    new_mean = np.mean(arr, axis=(0)) # calculate mean of all shapes adjusted to reference\n",
    "    \n",
    "    s1, s2, d = procrustes(old_mean, new_mean) # calculate procrustes distance of new mean to old mean\n",
    "    \n",
    "    print(\"the Procrustes distance between the old and new mean is\", d) # print out difference between mean distance\n",
    "    \n",
    "    old_mean = new_mean # set the old_mean to the new_mea before beginning another iteration\n",
    "    \n",
    "gpa_mean = new_mean # call the resulting mean leaf \"gpa_mean\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the Generalized Procrustes Analysis mean shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gpa_mean[:,0], gpa_mean[:,1])\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.axis(\"off\")\n",
    "#plt.savefig('/Users/asiahightower/Desktop/herbarium_paper_figures/individual_leaves/mean_leaf_US.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Procrustes-adjusted coordinates for each leaf against the calculated mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_number = np.shape(interpolated_data[0])[0] # get number of landmarks from first shape (it's the same for all)\n",
    "\n",
    "proc_arr = np.zeros( ((len(shapes)), landmark_number, 2) ) # empty 3D array: # samples, total landmarks, 2 coord vals\n",
    "\n",
    "for i in range(len(shapes)): # for each leaf shape \n",
    "\n",
    "    s1, s2, distance = procrustes(gpa_mean, interpolated_data[i]) # calculate procrustes adjusted shape to ref for current leaf\n",
    "    proc_arr[i] = s2 # store procrustes adjusted shape to array\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Procurestes shape data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(proc_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_arrdf = np.reshape(proc_arr, (523, 200*2))\n",
    "np.shape(proc_arrdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = np.column_stack([shapes,proc_arrdf])\n",
    "np.shape(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out_proc = pd.DataFrame(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out_proc.to_csv('file-path-proc_arrdf_phen.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visually check all Procrustes adjusted leaf shapes, plot with the gpa mean leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_col = \"k\" # set plot color\n",
    "a = 0.01 # set alpha\n",
    "\n",
    "for i in range(np.shape(proc_arr)[0]):\n",
    "    \n",
    "    curr_leaf = proc_arr[i,:,:]\n",
    "    \n",
    "    plt.plot(curr_leaf[:,0], curr_leaf[:,1], c=plot_col, alpha=a) # plot current leaf with color and alpha\n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "    \n",
    "plt.plot(gpa_mean[:,0], gpa_mean[:,1]) # plot the mean leaf\n",
    "\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.axis(\"off\")\n",
    "#plt.savefig('/Users/asiahightower/Desktop/herbarium_paper_figures/individual_leaves/mean_leaf_shadow.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Morphospace and Inverse Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find percent variance for each PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of samples from the list of shapes\n",
    "num_samples = len(interpolated_data) \n",
    "\n",
    "# from the first shape, get the total number of coordinates for each shape\n",
    "total_length = np.shape(interpolated_data[0])[0] \n",
    "\n",
    "# use the reshape function to flatten proc_arr to 2D, so that x and y coordinates are input into the PCA\n",
    "reshaped_arr = proc_arr.reshape(num_samples, total_length*2) \n",
    "\n",
    "# set number of PCs to number of samples, so we can see the percent variance for all PCs\n",
    "test_pca = PCA(n_components=304)\n",
    "\n",
    "# fit a PCA\n",
    "test_PCs = test_pca.fit_transform(reshaped_arr) \n",
    "\n",
    "# print out explained variance for each PC (a proportion)\n",
    "#print(test_pca.explained_variance_ratio_) \n",
    "\n",
    "#print out cumulative variance explained by PC (a proportion)\n",
    "#print(test_pca.explained_variance_ratio_.cumsum()) \n",
    "\n",
    "#\n",
    "print('Explained variation per principal component: {}'.format(test_pca.explained_variance_ratio_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an inverse PCA space and calculate PC points to reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define number of desired PCs\n",
    "# for reconstruction, it's easier to just use 2\n",
    "# but we can use more PC values if desired\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# apply the sklearn pca function with desired number of components\n",
    "\n",
    "PCs = pca.fit_transform(reshaped_arr)\n",
    "\n",
    "# the inverse transform function is applied\n",
    "\n",
    "inverse_PCA = pca.inverse_transform(PCs)\n",
    "\n",
    "# specify PC value to reconstruct\n",
    "# (this is just a test to make sure we can reconstruct \n",
    "# theoretical leaves using only PC values)\n",
    "\n",
    "PC1_val = 0.5\n",
    "PC2_val = 0\n",
    "\n",
    "# perform inverse PCA\n",
    "    \n",
    "inv_new = pca.inverse_transform(np.array([PC1_val,PC2_val]))\n",
    "\n",
    "# extract x and y vals, every other using the step indexing\n",
    "\n",
    "inv_xvals = inv_new[0::2]\n",
    "inv_yvals = inv_new[1::2]\n",
    "\n",
    "# plot the theoretical, reconstructed shape\n",
    "plt.plot(inv_xvals, inv_yvals)\n",
    "plt.gca().set_aspect(\"equal\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot background morphospace  \n",
    "\n",
    "To reduce the amount of code we are using, we will create a function to plot out a background morphospace. We can always come back to change the specifics of the function if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale, determined by checking, to prevent shape overlap\n",
    "scale = 0.5\n",
    "\n",
    "# padding on each side of PC to add extra space to see morphospace\n",
    "PC1_pad = 0.1\n",
    "PC2_pad = 0.1\n",
    "\n",
    "# number of intervals to divide each PC axis\n",
    "num_intervals = 5 \n",
    "\n",
    "# get PC1 interval values\n",
    "PC1_intervals = np.linspace( np.min(PCs[:,0]), np.max(PCs[:,0]) ,num_intervals)\n",
    "\n",
    "# get PC2 interval values\n",
    "PC2_intervals = np.linspace( np.min(PCs[:,1]), np.max(PCs[:,1]), num_intervals)\n",
    "\n",
    "for i in PC1_intervals:\n",
    "    \n",
    "    for j in PC2_intervals:\n",
    "        \n",
    "        # perform inverse PCA\n",
    "    \n",
    "        inv_new = pca.inverse_transform(np.array([i,j]))\n",
    "\n",
    "        # extract x and y vals, every other\n",
    "\n",
    "        inv_PC1_vals = inv_new[0::2]\n",
    "        inv_PC2_vals = inv_new[1::2]\n",
    "          \n",
    "        # scale so the shapes don't overlap, determine the right scale by checking\n",
    "        \n",
    "        scaled_PC1_vals = inv_PC1_vals*scale\n",
    "        scaled_PC2_vals = inv_PC2_vals*scale\n",
    "        \n",
    "        # translate to the PCA point position\n",
    "        \n",
    "        trans_PC1_vals = scaled_PC1_vals + i\n",
    "        trans_PC2_vals = scaled_PC2_vals + j\n",
    "        \n",
    "        # plot out the results to make sure it is correct\n",
    "\n",
    "        plt.fill(trans_PC1_vals, trans_PC2_vals, c=\"gray\", alpha=0.5)\n",
    "        plt.xlim( (np.min(PCs[:,0])-PC1_pad, np.max(PCs[:,0])+PC1_pad) )\n",
    "        plt.ylim( (np.min(PCs[:,1])-PC2_pad, np.max(PCs[:,1])+PC2_pad) )\n",
    "        plt.gca().set_aspect(\"equal\")\n",
    "#plt.savefig('/Users/asiahightower/Desktop/herbarium_paper_figures/individual_leaves/morphospace_all_5.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to plot background morphospace\n",
    "# inputs: scale, determined by checking, to prevent shape overlap in the plot. \n",
    "# PC1_pad and PC2_pad, padding on each side of PC to add extra space to see morphospace\n",
    "# num_intervals, number of intervals to divide each PC axis as a grid\n",
    "# output: a morphospace plot\n",
    "\n",
    "def Morphospace(scale, PC1_pad, PC2_pad, num_intervals, PCs):\n",
    "\n",
    "    # get PC1 interval values\n",
    "    PC1_intervals = np.linspace( np.min(PCs[:,0]), np.max(PCs[:,0]) ,num_intervals)\n",
    "\n",
    "    # get PC2 interval values\n",
    "    PC2_intervals = np.linspace( np.min(PCs[:,1]), np.max(PCs[:,1]), num_intervals)\n",
    "\n",
    "    for i in PC1_intervals:\n",
    "\n",
    "        for j in PC2_intervals:\n",
    "\n",
    "            # perform inverse PCA\n",
    "\n",
    "            inv_new = pca.inverse_transform(np.array([i,j]))\n",
    "\n",
    "            # extract x and y vals, every other\n",
    "\n",
    "            inv_PC1_vals = inv_new[0::2]\n",
    "            inv_PC2_vals = inv_new[1::2]\n",
    "\n",
    "            # scale so the shapes don't overlap, determine the right scale by checking\n",
    "\n",
    "            scaled_PC1_vals = inv_PC1_vals*scale\n",
    "            scaled_PC2_vals = inv_PC2_vals*scale\n",
    "\n",
    "            # translate to the PCA point position\n",
    "\n",
    "            trans_PC1_vals = scaled_PC1_vals + i\n",
    "            trans_PC2_vals = scaled_PC2_vals + j\n",
    "\n",
    "            # plot out the results to make sure it is correct\n",
    "\n",
    "            plt.fill(trans_PC1_vals, trans_PC2_vals, c=\"gray\", alpha=0.3)\n",
    "            plt.xlim( (np.min(PCs[:,0])-PC1_pad, np.max(PCs[:,0])+PC1_pad) )\n",
    "            plt.ylim( (np.min(PCs[:,1])-PC2_pad, np.max(PCs[:,1])+PC2_pad) )\n",
    "            plt.gca().set_aspect(\"equal\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check to see if the function works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale, determined by checking, to prevent shape overlap\n",
    "scale = 0.5\n",
    "\n",
    "# padding on each side of PC to add extra space to see morphospace\n",
    "PC1_pad = 0.1\n",
    "PC2_pad = 0.1\n",
    "\n",
    "# number of intervals to divide each PC axis\n",
    "num_intervals = 7 \n",
    "\n",
    "Morphospace(scale, PC1_pad, PC2_pad, num_intervals, PCs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate shape descriptors\n",
    "\n",
    "To measure lobing we will use circularity. We are currently using the circularity less used, which puts the area in the numerator and the perimeter in the denominator, so that 1 is a perfect circle and 0 deviates from that, but we can always switch these. Aspect ratio is calculated as width/length, and we use the fact that our leaves are oriented upright to simply take the min and max width and length values of leaves. We can figure out how to calculate solidity if needed as well, but maybe circularity is enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to calculate circularity\n",
    "\n",
    "# input: a 2D array of points for a polygon\n",
    "# output: circularity value, calculated as (4*pi*area)/perimeter**2\n",
    "# where 1 is a perfect circle and down to 0 for non-circular shapes\n",
    "\n",
    "\n",
    "def Circularity(shape_arr):\n",
    "    \n",
    "    lines = np.hstack([shape_arr,np.roll(shape_arr,-1,axis=0)])\n",
    "    area = 0.5*abs(sum(x1*y2-x2*y1 for x1,y1,x2,y2 in lines))\n",
    "    \n",
    "    distance = np.cumsum(np.sqrt( np.ediff1d(shape_arr[:,0], to_begin=0)**2 + np.ediff1d(shape_arr[:,1], to_begin=0)**2 ))\n",
    "    perimeter = distance[-1]\n",
    "    \n",
    "    circularity = (4*math.pi*area)/perimeter**2\n",
    "    \n",
    "    return circularity\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate circularity and aspect ratio values for all leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list to store circularity values\n",
    "circularity_vals = []\n",
    "\n",
    "# a list to store aspect ratio values (width divided by length)\n",
    "aspect_ratio_vals = []\n",
    "\n",
    "#length values \n",
    "length_vals = []\n",
    "\n",
    "#width values\n",
    "width_vals = []\n",
    "\n",
    "# for each Procrustes-adjusted shape\n",
    "for i in range(np.shape(proc_arr)[0]):\n",
    "    \n",
    "    # select current shape\n",
    "    curr_shape = proc_arr[i] \n",
    "    \n",
    "    # calculate circularity and append to list\n",
    "    circularity_vals.append(Circularity(curr_shape))\n",
    "    \n",
    "    # calculate length, width, and aspect ratio\n",
    "    length_vals.append(length)\n",
    "    width_vals.append(width)\n",
    "    aspect_ratio_vals.append(width/length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circdf = pd.DataFrame(circularity_vals, aspect_ratio_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a pandas dataframe to use seaborn, using a dictionary with the keys as column names and the values the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"PC1\":PCs[:,0], \"PC2\":PCs[:,1], \"circ\":circularity_vals, \"ar\":aspect_ratio_vals})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save df of pc's to use and combine weather data + plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('file-path-pc_circ_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a PC morphospace plot, points colored by circularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatterplot of PC values, colored by circularity (using hue in seaborn)\n",
    "sns.scatterplot(data=df, x=\"PC1\", y=\"PC2\", hue=\"circ\", palette = sns.color_palette(\"viridis\", as_cmap = True))\n",
    "\n",
    "# scale, determined by checking, to prevent shape overlap\n",
    "scale = 0.5\n",
    "\n",
    "# padding on each side of PC to add extra space to see morphospace\n",
    "PC1_pad = 0.1\n",
    "PC2_pad = 0.1\n",
    "\n",
    "# number of intervals to divide each PC axis\n",
    "num_intervals = 5 \n",
    "\n",
    "# use the morphospace function to create morphospace\n",
    "Morphospace(scale, PC1_pad, PC2_pad, num_intervals, PCs)\n",
    "\n",
    "# place the legend outside of the plot\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "#plt.savefig('/Users/asiahightower/Desktop/pca_circ_morphospace.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a PC morphospace plot, points colored by aspect ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatterplot of PC values, colored by aspect ratio (using hue in seaborn)\n",
    "sns.scatterplot(data=df, x=\"PC1\", y=\"PC2\", hue=\"ar\", palette = sns.color_palette(\"cubehelix\", as_cmap = True))\n",
    "\n",
    "# scale, determined by checking, to prevent shape overlap\n",
    "scale = 0.4\n",
    "\n",
    "# padding on each side of PC to add extra space to see morphospace\n",
    "PC1_pad = 0.1\n",
    "PC2_pad = 0.1\n",
    "\n",
    "# number of intervals to divide each PC axis\n",
    "num_intervals = 5 \n",
    "\n",
    "# use the morphospace function to create morphospace\n",
    "Morphospace(scale, PC1_pad, PC2_pad, num_intervals, PCs)\n",
    "\n",
    "# place the legend outside of the plot\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "#plt.savefig('/Users/asiahightower/Desktop/pca_aspectratio_morphospace.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find closest matches to archetypal leaves\n",
    "\n",
    "For a given leaf, find its closest match to a set of archetypepal leaves using Procrustes distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ianetta 7 leaf shapes\n",
    "# a list of the shapes to compare to\n",
    "# in this case, I will use A1, B1, C1, and D1\n",
    "# which are indices 0, 4, 8, and 12\n",
    "\n",
    "archetypes = [proc_arr[507], proc_arr[508], proc_arr[509], proc_arr[510], proc_arr[511], proc_arr[512], proc_arr[513],\n",
    "              proc_arr[514], proc_arr[515], proc_arr[516], proc_arr[517], proc_arr[518]]\n",
    "\n",
    "# create a list of names to refer to them as\n",
    "names = [\"Type1a1\", \"Type1a2\", \"Type1a3\", \"Type1a4\", \"Type2a1\", \"Type2a2\", \"Type3\", \"Type4\", \"Type5\", \"Type6\", \n",
    "        \"Type7a\", \"Type7b\"]\n",
    "\n",
    "# create a list to store the closest matched archetype to each leaf\n",
    "closest_matches_iannetta = []\n",
    "\n",
    "# for each shape\n",
    "for i in range(len(shapes)):\n",
    "    \n",
    "    # select the current shape\n",
    "    curr_shape = proc_arr[i]\n",
    "    \n",
    "    # create a list of distances of the current shape to each archetype\n",
    "    archetype_dist = []\n",
    "    \n",
    "    # for each archetype\n",
    "    for j in range(len(names)):\n",
    "        \n",
    "        # calculate Procrustes distance between archetype and current shape\n",
    "        s1, s2, distance = procrustes(archetypes[j], curr_shape) \n",
    "        \n",
    "        # append distance to list of distances\n",
    "        archetype_dist.append(distance)\n",
    "    \n",
    "    # find index of closest archetype to current leaf\n",
    "    archetype_index = archetype_dist.index(min(archetype_dist))\n",
    "    \n",
    "    # get name of closest archetype to current leaf using the index\n",
    "    archetype_name = names[archetype_index]\n",
    "    \n",
    "    # append the closest match to list\n",
    "    closest_matches_iannetta.append(archetype_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to the dataframe that already has PC1, PC2, circularity, and aspect ratio, and best_match\n",
    "\n",
    "df[\"best_match_iannetta\"] = closest_matches_iannetta\n",
    "\n",
    "df.head()\n",
    "\n",
    "#df.to_csv('/Users/asiahightower/Desktop/bestmatches.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the data and color by best match\n",
    "\n",
    "# scatterplot of PC values, colored by best_match (using hue in seaborn)\n",
    "sns.scatterplot(data=df, x=\"PC1\", y=\"PC2\", hue=\"best_match_iannetta\", palette = sns.color_palette('colorblind'))\n",
    "\n",
    "# scale, determined by checking, to prevent shape overlap\n",
    "scale = 0.4\n",
    "\n",
    "# padding on each side of PC to add extra space to see morphospace\n",
    "PC1_pad = 0.1\n",
    "PC2_pad = 0.1\n",
    "\n",
    "# number of intervals to divide each PC axis\n",
    "num_intervals = 5 \n",
    "\n",
    "# use the morphospace function to create morphospace\n",
    "Morphospace(scale, PC1_pad, PC2_pad, num_intervals, PCs)\n",
    "\n",
    "# place the legend outside of the plot\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "#plt.savefig('/Users/asiahightower/Desktop/colorandbestmatch.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shull 4 leaf shapes \n",
    "# a list of the shapes to compare to\n",
    "# in this case, I will use A1, B1, C1, and D1\n",
    "# which are indices 0, 4, 8, and 12\n",
    "\n",
    "archetypes = [proc_arr[521], proc_arr[520], proc_arr[522], proc_arr[519]]\n",
    "\n",
    "# create a list of names to refer to them as\n",
    "names = [\"simplex\", \"rhomboidea\", \"tenuis\", \"heteris\"]\n",
    "\n",
    "# create a list to store the closest matched archetype to each leaf\n",
    "closest_matches_shull = []\n",
    "\n",
    "# for each shape\n",
    "for i in range(len(shapes)):\n",
    "    \n",
    "    # select the current shape\n",
    "    curr_shape = proc_arr[i]\n",
    "    \n",
    "    # create a list of distances of the current shape to each archetype\n",
    "    archetype_dist = []\n",
    "    \n",
    "    # for each archetype\n",
    "    for j in range(len(names)):\n",
    "        \n",
    "        # calculate Procrustes distance between archetype and current shape\n",
    "        s1, s2, distance = procrustes(archetypes[j], curr_shape) \n",
    "        \n",
    "        # append distance to list of distances\n",
    "        archetype_dist.append(distance)\n",
    "    \n",
    "    # find index of closest archetype to current leaf\n",
    "    archetype_index = archetype_dist.index(min(archetype_dist))\n",
    "    \n",
    "    # get name of closest archetype to current leaf using the index\n",
    "    archetype_name = names[archetype_index]\n",
    "    \n",
    "    # append the closest match to list\n",
    "    closest_matches_shull.append(archetype_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to the dataframe that already has PC1, PC2, circularity, and aspect ratio, and best_match\n",
    "\n",
    "df[\"best_match_shull\"] = closest_matches_shull\n",
    "\n",
    "df.head()\n",
    "\n",
    "#df.to_csv('/Users/asiahightower/Desktop/bestmatches2.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the data and color by best match\n",
    "\n",
    "# scatterplot of PC values, colored by best_match (using hue in seaborn)\n",
    "sns.scatterplot(data=df, x=\"PC1\", y=\"PC2\", hue=\"best_match_shull\", palette = sns.color_palette('colorblind'))\n",
    "\n",
    "# scale, determined by checking, to prevent shape overlap\n",
    "scale = 0.4\n",
    "\n",
    "# padding on each side of PC to add extra space to see morphospace\n",
    "PC1_pad = 0.1\n",
    "PC2_pad = 0.1\n",
    "\n",
    "# number of intervals to divide each PC axis\n",
    "num_intervals = 5\n",
    "\n",
    "# use the morphospace function to create morphospace\n",
    "Morphospace(scale, PC1_pad, PC2_pad, num_intervals, PCs)\n",
    "\n",
    "# place the legend outside of the plot\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "#plt.savefig('/Users/asiahightower/Desktop/bestmatchshull.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting by pheno + pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pc_metadata = pd.read_csv('/Users/asiahightower/Desktop/desktop_csv_files/herb_pc_circ_data_complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in pc_metadata.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3 = pc_metadata.loc[pc_metadata[\"type_shull\"] == \"rhomboidea\"]\n",
    "df3.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
